{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación Final Módulo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Imputación de nulos usando métodos avanzados estadísticos\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Librerías de visualización\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuración\n",
    "\n",
    "pd.set_option('display.max_columns', None) # para poder visualizar todas las columnas de los DataFrames\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 1. Exploración y limpieza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploración csv: 'Customer Flight Activity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar csv 'Customer Flight Activity'\n",
    "df_cfa = pd.read_csv(\"data/Customer Flight Activity.csv\", index_col=0)\n",
    "df_cfa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restablecer el índice para convertir 'Loyalty Number' en una columna:\n",
    "df_cfa.reset_index(inplace=True)\n",
    "df_cfa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploración de columnas: \n",
    "df_cfa.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de filas y columnas:\n",
    "print(f\"El número de filas que tenemos es {df_cfa.shape[0]}, y el número de columnas es {df_cfa.shape[1]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la estructura:\n",
    "df_cfa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización estadísticas descriptivas de las columnas numéricas:\n",
    "df_cfa.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización cantidad de valores únicos de todas las columnas:\n",
    "df_cfa.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploración de los valores únicos de cada columna:\n",
    "\n",
    "def print_unique_values(df_cfa):\n",
    "    for column in df_cfa.columns:\n",
    "        unique_values = df_cfa[column].unique()\n",
    "        num_unique = len(unique_values)\n",
    "        print(f\"Columna: {column}\")\n",
    "        print(f\"Número de valores únicos: {num_unique}\")\n",
    "        print(f\"Valores únicos: {unique_values}\")\n",
    "        print(\"-\" * 40)\n",
    "print_unique_values(df_cfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobación de Nulos: \n",
    "df_cfa.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para explorar el número de duplicados por columna: \n",
    "\n",
    "def check_duplicates_in_columns(df_cfa):\n",
    "   \n",
    "    for column in df_cfa.columns:\n",
    "        # Identificar los valores duplicados en la columna\n",
    "        duplicates = df_cfa[column].duplicated(keep=False)\n",
    "        \n",
    "        # Contar el número de duplicados en la columna\n",
    "        num_duplicates = duplicates.sum()\n",
    "        \n",
    "        if num_duplicates > 0:\n",
    "            print(f\"Columna '{column}' tiene {num_duplicates} duplicados.\")\n",
    "        else:\n",
    "            print(f\"Columna '{column}' no tiene duplicados.\")\n",
    "check_duplicates_in_columns(df_cfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar el DataFrame por 'Loyalty Number'\n",
    "df_sorted = df_cfa.sort_values(by='Loyalty Number')\n",
    "\n",
    "# Filtrar las filas duplicadas en 'Loyalty Number' (única columna que a priori podría ser conflictiva en términos de duplicados):\n",
    "duplicates = df_sorted[df_sorted.duplicated(subset='Loyalty Number', keep=False)]\n",
    "\n",
    "duplicates.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! Se decide no eliminar duplicados, ya que es necesario mantener los distintos registros de las distintas fechas !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLORACIÓN 'Customer Loyalty History'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar csv 'Customer Loyalty History':\n",
    "df_clh = pd.read_csv(\"data/Customer Loyalty History.csv\")\n",
    "df_clh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploración de columnas:\n",
    "df_clh.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de filas y columnas:\n",
    "print(f\"El número de filas que tenemos es {df_clh.shape[0]}, y el número de columnas es {df_clh.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la estructura:\n",
    "\n",
    "df_clh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización estadísticas descriptivas de las columnas numéricas:\n",
    "df_clh.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización estadísticas descriptivas de las columnas categóricas o tipo object:\n",
    "df_clh.describe(include=\"object\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualicación cantidad de valores únicos de cada columna:\n",
    "df_clh.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para explorar los valores únicos de cada columna:\n",
    "\n",
    "def print_unique_values(df_clh):\n",
    "    for column in df_clh.columns:\n",
    "        unique_values = df_clh[column].unique()\n",
    "        num_unique = len(unique_values)\n",
    "        print(f\"Columna: {column}\")\n",
    "        print(f\"Número de valores únicos: {num_unique}\")\n",
    "        print(f\"Valores únicos: {unique_values}\")\n",
    "        print(\"-\" * 40)\n",
    "print_unique_values(df_clh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobación de nulos:\n",
    "df_clh.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar que en la columna Loyalty Number (única columna que podría ser conflictiva en términos de duplicados) todos los valores son únicos:\n",
    "num_duplicates = df_clh['Loyalty Number'].duplicated().sum()\n",
    "print(f\"Número de valores duplicados en 'Loyalty Number': {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Transformación y Limpieza: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir las columnas 'Year' y 'Month' de 'df_cfa' en una columna de tipo datetime: \n",
    "\n",
    "df_cfa['Date'] = pd.to_datetime(df_cfa['Year'].astype(str) + '-' + df_cfa['Month'].astype(str) + '-01')\n",
    "\n",
    "# Eliminar las columnas originales de 'Year' y 'Month':\n",
    "\n",
    "df_cfa.drop(columns=['Year', 'Month'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para unir columnas del 'df_clh' en una columna de tipo date time y eliminar las originales:\n",
    "\n",
    "def create_date_columns(df_clh, enrollment_year_col, enrollment_month_col, cancellation_year_col, cancellation_month_col):\n",
    "    df_clh['Enrollment Date'] = pd.to_datetime(df_clh[enrollment_year_col].astype(str) + '-' + df_clh[enrollment_month_col].astype(str) + '-01', errors='coerce')\n",
    "    df_clh['Cancellation Date'] = pd.to_datetime(df_clh[cancellation_year_col].astype('Int64').astype(str) + '-' + df_clh[cancellation_month_col].astype('Int64').astype(str) + '-01', errors='coerce')\n",
    "    df_clh.drop(columns=[enrollment_year_col, enrollment_month_col, cancellation_year_col, cancellation_month_col], inplace=True)\n",
    "\n",
    "    return df_clh\n",
    "\n",
    "df_clh = create_date_columns(df_clh, 'Enrollment Year', 'Enrollment Month', 'Cancellation Year', 'Cancellation Month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar tipo de dato de columnas de 'df_cfa':\n",
    "\n",
    "columns_to_convert = ['Distance', 'Points Accumulated', 'Points Redeemed', 'Dollar Cost Points Redeemed']\n",
    "df_cfa[columns_to_convert] = df_cfa[columns_to_convert].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar tipo de dato de las columnas de df_clh:\n",
    "\n",
    "categorical_columns = ['Country', 'Province', 'City', 'Gender', 'Education', 'Marital Status', 'Loyalty Card', 'Enrollment Type']\n",
    "df_clh[categorical_columns] = df_clh[categorical_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular los porcentajes de nulos para valorar la imputación:\n",
    "\n",
    "total_rows =len(df_clh)\n",
    "null_counts = df_clh.isnull().sum()\n",
    "null_counts_filtered = null_counts[null_counts > 0]\n",
    "null_percentages = (null_counts_filtered/ total_rows) * 100\n",
    "null_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra las filas donde 'Salary' es nulo y contar la cantidad de valores nulos en 'Salary' por cada categoría de 'Education':\n",
    "\n",
    "nulos_salary = df_clh[df_clh['Salary'].isnull()]\n",
    "categoria_nulos = nulos_salary['Education'].value_counts()\n",
    "\n",
    "print(\"Categorías de 'Education' con valores nulos en 'Salary':\")\n",
    "print(categoria_nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputar con 0 los nulos de la columna \"Salary\", ya que corresponden a la categoría \"College\" de la columna \"Education\" y se entiende que no tienen salario: \n",
    "\n",
    "df_clh.loc[df_clh['Education'] == 'College', 'Salary'] = df_clh.loc[df_clh['Education'] == 'College', 'Salary'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular la cantidad de valores negativos en la columna \"Salary\":\n",
    "\n",
    "negative_count = (df_clh['Salary'] < 0).sum()\n",
    "negative_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los registros con valores negativos en la columna \"Salary\":\n",
    "\n",
    "negative_salaries = df_clh[df_clh['Salary'] < 0]\n",
    "negative_salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir los valores negativos a positivos usando numpy (Por el tipo de valores que se observan, se interpreta que ha habido un problema de introducción de datos):\n",
    "\n",
    "df_clh['Salary'] = np.abs(df_clh['Salary'])\n",
    "\n",
    "#----> También se podría hacer con apply: df_clh['Salary'] = df_clh['Salary'].apply(lambda x: abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir los valores nulos de la columna \"Cancellation Date\" a \"-\", ya que se interpreta que sigue vigente:\n",
    "\n",
    "df_clh['Cancellation Date'] = df_clh['Cancellation Date'].fillna('-')\n",
    "print(\"Número de nulos en 'Cancellation Date' después de imputación:\", df_clh['Cancellation Date'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unión de los csv:\n",
    "\n",
    "df_cfalh = pd.merge(df_cfa, df_clh, on='Loyalty Number', how='inner')\n",
    "df_cfalh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FASE 2. Visualización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. ¿Cómo se distribuye la cantidad de vuelos reservados por mes durante el año?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una columna 'Year-Month' para el análisis mensual:\n",
    "\n",
    "df_cfalh['Year-Month'] = df_cfalh['Date'].dt.to_period('M') \n",
    "\n",
    "# Agrupar por mes y sumar la cantidad de vuelos reservados:\n",
    "\n",
    "monthly_flights = df_cfalh.groupby('Year-Month')['Flights Booked'].sum().reset_index()\n",
    "\n",
    "# Gráfico:\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.plot(monthly_flights['Year-Month'].astype(str), monthly_flights['Flights Booked'], marker='o', linestyle='-')\n",
    "\n",
    "plt.xlabel('Año-Mes')\n",
    "plt.ylabel('Vuelos reservados')\n",
    "plt.title('Distribución de Vuelos Reservados por Mes durante el Año')\n",
    "plt.xticks(rotation=45)  # Rotar etiquetas del eje x para mejor visibilidad\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout() # Márgenes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Estacionalidad: Los picos de vuelos reservados en los meses de verano y Navidad indican un mayor número de reservas durante ciertos períodos del año que implican vacaciones o festividades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. ¿Existe una relación entre la distancia de los vuelos y los puntos acumulados por los clientes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la correlación de Pearson entre distancia y puntos acumulados:\n",
    "\n",
    "correlation = df_cfalh['Distance'].corr(df_cfalh['Points Accumulated'])\n",
    "\n",
    "print(f'Correlación entre Distance y Points Accumulated: {correlation:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Crear un gráfico de dispersión con color por la categoría Loyalty Card:\n",
    "\n",
    "sns.scatterplot(data=df_cfalh, x='Distance', y='Points Accumulated', hue='Loyalty Card')\n",
    "\n",
    "plt.xlabel('Distancia')\n",
    "plt.ylabel('Puntos Acumulados')\n",
    "plt.title('Relación entre Distancia de los Vuelos y Puntos Acumulados por Categoría')\n",
    "plt.legend(title='Targeta de Fidelización')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Relación positiva: las diferentes categorías de tarjetas pueden mostrar variaciones en la cantidad de puntos acumulados por distancia, pero todas muestran una tendencia general de mayor acumulación de puntos con una mayor distancia. \n",
    "- Esto sugiere que hay una diferencia en la generosidad de las recompensas entre los tipos de tarjeta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ¿Cuál es la distribución de los clientes por provincia o estado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de clientes por Provincia\n",
    "provincia_counts = df_cfalh['Province'].value_counts()\n",
    "\n",
    "# Convertir a DataFrame para facilitar la visualización\n",
    "provincia_df = provincia_counts.reset_index()\n",
    "provincia_df.columns = ['Province', 'Number of Clients']\n",
    "\n",
    "# Gráfico:\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.barplot(data=provincia_df, x='Province', y='Number of Clients', palette='viridis')\n",
    "plt.xlabel('Provincia')\n",
    "plt.ylabel('Número de Clientes')\n",
    "plt.title('Distribución de Clientes por Provincia')\n",
    "plt.xticks(rotation=45)  # Rotar etiquetas del eje \n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El gráfico simplemente revela las provincias con mayor número de clientes. \n",
    "- Las provincias con un alto número de clientes podrían ser el foco para estrategias de marketing y servicio, mientras que provincias con menos clientes podrían necesitar esfuerzos adicionales para aumentar la base de clientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ¿Cómo se compara el salario promedio entre los diferentes niveles educativos de los clientes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salario promedio por nivel educativo\n",
    "salary_by_education = df_cfalh.groupby('Education')['Salary'].mean().reset_index()\n",
    "\n",
    "# Renombrar las columnas\n",
    "salary_by_education.columns = ['Education', 'Average Salary']\n",
    "\n",
    "# Gráfico:\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.barplot(data=salary_by_education, x='Education', y='Average Salary', palette='viridis')\n",
    "\n",
    "plt.xlabel('Nivel Educativo')\n",
    "plt.ylabel('Salario Promedio')\n",
    "plt.title('Salario Promedio por Nivel Educativo')\n",
    "plt.xticks(rotation=45) \n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot:\n",
    "\n",
    "df_filtered = df_cfalh[df_cfalh['Education'] != 'College']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "sns.boxplot(data=df_filtered, x='Education', y='Salary', palette='Set2')\n",
    "\n",
    "plt.xlabel('Nivel Educativo', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Salario', fontsize=14, fontweight='bold')\n",
    "plt.title('Distribución de Salarios por Nivel Educativo (sin College)', fontsize=16, fontweight='bold')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se observan diferencias significativas entre los salarios promedio de diferentes niveles educativos, reflejando cómo un nivel más alto de educación (Doctor) influye positivamente en el nivel de ingresos.\n",
    "- Utilizando el boxplot se pueden apreciar los outliers que corresponden a los salarios atípicos más bajos en el caso de \"Bachelor\" y \"High School or Below\", así como los outliers con valores que representan salarios atípicos más altos, como es el caso de la categoría \"Doctor\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. ¿Cuál es la proporción de clientes con diferentes tipos de tarjetas de fidelidad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de clientes por tipo de tarjeta\n",
    "loyalty_card_counts = df_cfalh['Loyalty Card'].value_counts()\n",
    "\n",
    "# Calcular las proporciones\n",
    "loyalty_card_proportions = loyalty_card_counts / loyalty_card_counts.sum()\n",
    "\n",
    "# Gráfico\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.pie(loyalty_card_proportions, labels=loyalty_card_proportions.index, autopct='%1.1f%%', colors=['#ff9999','#66b3ff','#99ff99','#ffcc99'])\n",
    "plt.title('Proporción de Clientes por Tipo de Tarjeta de Fidelidad')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se puede identificar que la targeta Star tiene la mayor proporción de clientes. \n",
    "- Como se puede comprobar en el gráfico 'Relación entre Distancia de los Vuelos y Puntos Acumulados por Categoría', seguramente es debido a que es la targeta con un coste más bajo. \n",
    "- A priori se podría concluir que los beneficios de la targeta Aurora no compensan su precio, en relación con las targetas de menor categoría."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. ¿ Cómo se distribuyen los clientes según su estado civil y género?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una tabla de contingencia\n",
    "contingency_table = pd.crosstab(index=df_cfalh['Marital Status'], columns=df_cfalh['Gender'])\n",
    "\n",
    "# Mostrar la tabla de contingencia\n",
    "print(\"Tabla de Contingencia:\")\n",
    "print(contingency_table)\n",
    "\n",
    "# Gráfico\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "contingency_table.plot(kind='bar', figsize=(12, 8))\n",
    "\n",
    "plt.xlabel('Estado Civil')\n",
    "plt.ylabel('Número de Clientes')\n",
    "plt.title('Distribución de Clientes según Estado Civil y Género')\n",
    "plt.legend(title='Género')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap:\n",
    "\n",
    "contingency_table = pd.crosstab(index=df_cfalh['Marital Status'], columns=df_cfalh['Gender'])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "sns.heatmap(contingency_table, annot=True, cmap='YlGnBu', fmt='d')\n",
    "\n",
    "plt.xlabel('Género')\n",
    "plt.ylabel('Estado Civil')\n",
    "plt.title('Distribución de Clientes según Estado Civil y Género')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se observa como no hay diferencias significativas entre géneros en las distintas categorías. \n",
    "- El mayor número de clientes corresponde a la categoría de casados, mientras que el menor número de clientes corresponde a la categoría de divorciados. \n",
    "- La diferencia de cantidades de clientes entre categorías es significativa, sobretodo para la categoría de casados. Esto podría indicar que las personas casadas tienden a contratar programas de fidelización. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FASE 3. Evaluación de Diferencias en Reservas de Vuelos por Nivel Educativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hipótesis:\n",
    "\n",
    "    - H0​: No hay una diferencia significativa en el número promedio de vuelos reservados entre los grupos de \"Secondary Education\" y \"Higher Education\".\n",
    "    - H1​: Hay una diferencia significativa en el número promedio de vuelos reservados entre los grupos de \"Secondary Education\" y \"Higher Education\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preparación de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar niveles educativos\n",
    "group_a = ['High School', 'College']  # Educación secundaria\n",
    "group_b = ['Bachelor', 'Master', 'Doctorate']  # Educación superior\n",
    "\n",
    "# Crear una nueva columna para el grupo\n",
    "df_cfalh['Education Group'] = df_cfalh['Education'].apply(lambda x: 'Secondary Education' if x in group_a else 'Higher Education')\n",
    "\n",
    "# Filtrar el DataFrame para incluir solo las columnas relevantes\n",
    "df_ab_test = df_cfalh[['Flights Booked', 'Education Group']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualización estadísticas descriptivas de ambos grupos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular estadísticas descriptivas por grupo de educación\n",
    "descriptive_stats_ab = df_ab_test.groupby('Education Group')['Flights Booked'].describe()\n",
    "descriptive_stats_ab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pruebas de Normalidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# Filtrar los datos por grupo\n",
    "group_a_data = df_ab_test[df_ab_test['Education Group'] == 'Secondary Education']['Flights Booked']\n",
    "group_b_data = df_ab_test[df_ab_test['Education Group'] == 'Higher Education']['Flights Booked']\n",
    "\n",
    "# Valor predeterminado de alpha\n",
    "alpha = 0.05\n",
    "\n",
    "# Prueba de normalidad para el Grupo A\n",
    "stat_a, p_value_a = shapiro(group_a_data)\n",
    "normality_a = \"normal\" if p_value_a > alpha else \"no normal\"\n",
    "print(f\"Grupo A - Prueba de Normalidad Shapiro-Wilk p-value: {p_value_a:.4e} (Resultado: {normality_a})\")\n",
    "\n",
    "# Prueba de normalidad para el Grupo B\n",
    "stat_b, p_value_b = shapiro(group_b_data)\n",
    "normality_b = \"normal\" if p_value_b > alpha else \"no normal\"\n",
    "print(f\"Grupo B - Prueba de Normalidad Shapiro-Wilk p-value: {p_value_b:.4e} (Resultado: {normality_b})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualización distribución no normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Histograma y curva de densidad para el Grupo A\n",
    "sns.histplot(df_ab_test[df_ab_test['Education Group'] == 'Secondary Education']['Flights Booked'], kde=True, label='Secondary Education', color='blue', alpha=0.6)\n",
    "sns.histplot(df_ab_test[df_ab_test['Education Group'] == 'Higher Education']['Flights Booked'], kde=True, label='Higher Education', color='orange', alpha=0.6)\n",
    "\n",
    "# Configurar etiquetas y título\n",
    "plt.xlabel('Vuelos Reservados')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Histograma con Curva de Densidad de Vuelos Reservados por Nivel Educativo')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Como la distribución de datos no es normal, se utiliza la prueba no paramétrica de Mann-Whitney U:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Prueba de Mann-Whitney U\n",
    "u_stat, p_value = mannwhitneyu(group_a_data, group_b_data, alternative='two-sided')\n",
    "print(f\"Prueba Mann-Whitney U - Estadístico U: {u_stat:.2f}, p-value: {p_value:.2f}\")\n",
    "\n",
    "# Evaluar si rechazar H0\n",
    "if p_value < alpha:\n",
    "    print(\"Rechazamos la hipótesis nula. Existe una diferencia significativa en el número de vuelos reservados entre los dos grupos.\")\n",
    "else:\n",
    "    print(\"No rechazamos la hipótesis nula. No hay evidencia suficiente para afirmar que existe una diferencia significativa en el número de vuelos reservados entre los dos grupos.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSIÓN\n",
    "- Los resultados de la prueba Mann-Whitney U muestran un estadístico U de 15,631,115,821.00 y un valor p de 0.01. \n",
    "- Dado que el valor p es menor que el nivel de significancia (α = 0.05), se rechaza la hipótesis nula, indicando que existe una diferencia estadísticamente significativa en el número de vuelos reservados entre los dos grupos comparados. \n",
    "- Los datos obtenidos sugieren que las diferencias en el número de vuelos reservados no se deben al azar y que, en efecto, hay una discrepancia significativa en la conducta de reserva entre los grupos evaluados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
